Ядро фреймворка.

### Сборка из docker-compose
Проект собирается из корня с помощью команды

``docker-compose build --no-cache``

Фреймворк состоит из двух сервисов:
- df: собственно фреймворк, который взаимодействует с метаданными и умеет собирать графы airflow
- neo4j: база данных, в которую записываются графы перед тем, как из них собираются даги Airflow или любого другого движка
             
Чтобы запустить сервис, нужно ввести команду

``docker-compose run df /bin/bash``

### Запуск скриптов 
Чтобы собрать тестовый dag, нужно в терминале ввести следующие команды:

``python scripts/define_metadata.py``

``python scripts/fill_metadata.py``

### Абстракции
Фреймворк использует значительное количество абстракций, информация о
которых хранится в базе с метаданными; первая команда определяет схему
таблиц этой базы данных.

Вторая команда исполняет скрипт, с помощью которого в таблицы этой 
базы записывается информация об абстракциях и их реализациях.

Важно: в комментариях к скрипту fill_metadata.py подробно описано,
зачем нужна каждая из этих сущностей.

### Обучение модели
Чтобы ознакомиться с функциональностью, связанной с тренировкой моделей,
нужно выполнить следующие команды:

``python scripts/define_metadata.py``

``python scripts/fill_metadata_iris.py``

Как dag'и, так и натренированные модели сохраняются в специальных папках,
подключенных как data volumes; похожим образом за пределы фреймворка
вынесены папки с процессорами и драйверами.

### Airflow
Airflow - не часть фреймворка; он должен быть установлен отдельно вместе
с другими пакетами, указанными в файле requirements.txt.

### Внешние источники
Postgres, который используется в примерах:

``docker run --rm -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=postgres -p 5432:5432 -v pgdata:/var/lib/postgresql/data --name postgres postgres``

